{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXfKIoKbTk-o",
        "outputId": "37c81388-d483-4d8e-9f39-68066748f505"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Loading tokenizer: uitnlp/CafeBERT\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using CLS token: '<s>', SEP token: '</s>'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import torch # Import torch at a higher level\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "from collections import Counter\n",
        "import unicodedata # Kept if you plan to use it later for more advanced text cleaning\n",
        "import re # Kept for potential advanced text cleaning\n",
        "from google.colab import drive\n",
        "from huggingface_hub import login\n",
        "\n",
        "\n",
        "# --- Configuration ---\n",
        "MODEL_NAME = \"uitnlp/CafeBERT\"\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/ChongPha_Ver2/VisoBERT/OUTPUT'\n",
        "LOGGING_DIR = '/content/drive/MyDrive/ChongPha_Ver2/VisoBERT/LOGGING'\n",
        "DATASET_PATH = \"/content/drive/MyDrive/ChongPha_Ver2/Dataset_ChongPha.csv\"\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "# login(token='YOUR_HF_TOKEN_HERE')\n",
        "\n",
        "# Define labels and their mapping (ensure this order is consistent)\n",
        "# This mapping will be used by the Dataset class and for the classification report\n",
        "LABELS = [\"PHAN_DONG\", \"KHONG_PHAN_DONG\", \"KHONG_LIEN_QUAN\"]\n",
        "LABEL_TO_ID = {label: i for i, label in enumerate(LABELS)}\n",
        "ID_TO_LABEL = {i: label for i, label in enumerate(LABELS)}\n",
        "NUM_LABELS = len(LABELS)\n",
        "\n",
        "print(f\"Loading tokenizer: {MODEL_NAME}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "ACTUAL_CLS_TOKEN = tokenizer.cls_token # e.g., '<s>' for PhoBERT\n",
        "ACTUAL_SEP_TOKEN = tokenizer.sep_token # e.g., '</s>' for PhoBERT\n",
        "print(f\"Using CLS token: '{ACTUAL_CLS_TOKEN}', SEP token: '{ACTUAL_SEP_TOKEN}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UH5B-9HiTny9",
        "outputId": "1b08bd29-84d3-4a56-bc92-5319b0fab800"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Total examples: 18912\n",
            "Train examples: 15129, Validation examples: 1891, Test examples: 1892\n",
            "\n",
            "Original dataset label distribution:\n",
            "label\n",
            "KHONG_LIEN_QUAN    0.528976\n",
            "KHONG_PHAN_DONG    0.356599\n",
            "PHAN_DONG          0.114425\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Training set label distribution:\n",
            "label\n",
            "KHONG_LIEN_QUAN    0.528984\n",
            "KHONG_PHAN_DONG    0.356600\n",
            "PHAN_DONG          0.114416\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Validation set label distribution:\n",
            "label\n",
            "KHONG_LIEN_QUAN    0.528821\n",
            "KHONG_PHAN_DONG    0.356425\n",
            "PHAN_DONG          0.114754\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Test set label distribution:\n",
            "label\n",
            "KHONG_LIEN_QUAN    0.529070\n",
            "KHONG_PHAN_DONG    0.356765\n",
            "PHAN_DONG          0.114165\n",
            "Name: proportion, dtype: float64\n",
            "Sample train text: <s> 1. Nội dung sơ lược: Bài viết thể hiện sự bất bình về việc chính phủ Việt Nam ăn mừng ngày 30/4, cho rằng đó là ngày 'nồi da xáo thịt' và lên án việc 'nhồi sọ' thế hệ trẻ về lịch sử, đặc biệt là về mối quan hệ với Trung Quốc.\n",
            "\n",
            "2. Vấn đề: Phản đối chính phủ Việt Nam, cáo buộc xuyên tạc lịch sử, và chỉ trích quan hệ Việt - Trung.\n",
            "\n",
            "3. Phản động/tin giả: có, nội dung xuyên tạc lịch sử, kích động hận thù, chống phá chính quyền. </s> không thấy nhục à mà suốt ngày vươn cổ về nói việt nam thế này việt nam thế kia hãy nghe người dân đang sinh sống và làm việc tại việt nam họ thấy vui mừng hp vì ngày nay được hưởng thái bình cơm no áo ấm y tế tốt an ninh tốt mọi thứ đều tốt họ không kêu than thì mắc gì chúng mày cứ than hộ không công như vậy thấy mệt mỏi với chúng mày thật ấy chứ </s>...\n",
            "Sample train label: KHONG_PHAN_DONG\n",
            "Unique labels in training data: ['KHONG_PHAN_DONG' 'KHONG_LIEN_QUAN' 'PHAN_DONG']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "def load_and_prepare_data(file_path, cls_token, sep_token, combine_summary_comment=True):\n",
        "    df = pd.read_csv(file_path)\n",
        "    if combine_summary_comment:\n",
        "        df['summary'] = df['summary'].astype(str).fillna('')\n",
        "        df['comment_clean'] = df['comment_clean'].astype(str).fillna('')\n",
        "\n",
        "        # Manually construct the full string with all special tokens\n",
        "        df['text'] = f\"{cls_token} \" + df['summary'] + f\" {sep_token} \" + df['comment_clean'] + f\" {sep_token}\"\n",
        "    else: # Fallback for single comment - add CLS and SEP\n",
        "        df['comment_clean'] = df['comment'].astype(str).fillna('') # Assuming 'comment' if not combining\n",
        "        df['text'] = f\"{cls_token} \" + df['comment_clean'] + f\" {sep_token}\"\n",
        "\n",
        "    df['label'] = df['label'].astype(str)\n",
        "    # Assuming LABELS is defined globally for validation\n",
        "    unknown_labels = set(df['label']) - set(LABELS)\n",
        "    if unknown_labels:\n",
        "        raise ValueError(f\"Unknown labels found in {file_path}: {unknown_labels}. Expected labels are: {LABELS}\")\n",
        "    return df['text'], df['label']\n",
        "print(\"Loading data...\")\n",
        "\n",
        "try:\n",
        "    # Unpack the tuple returned by load_and_prepare_data\n",
        "    data_texts, data_labels_str = load_and_prepare_data(DATASET_PATH, cls_token=ACTUAL_CLS_TOKEN, sep_token=ACTUAL_SEP_TOKEN)\n",
        "\n",
        "    train_texts, temp_texts, train_labels_str, temp_labels_str = train_test_split(\n",
        "        data_texts,          # Features\n",
        "        data_labels_str,     # Labels (original strings)\n",
        "        test_size=0.2,       # 30% for temp_texts and temp_labels_str\n",
        "        random_state=2025,     # For reproducibility\n",
        "        stratify=data_labels_str # Ensures proportional distribution based on these labels\n",
        "    )\n",
        "\n",
        "    # --- Second Split: (Validation vs. Test from Temp) ---\n",
        "    # Splitting the 30% temporary set into 50% validation and 50% test\n",
        "    # (which is 15% of original for val, 15% of original for test)\n",
        "    # We stratify based on 'temp_labels_str'.\n",
        "    val_texts, test_texts, val_labels_str, test_labels_str = train_test_split(\n",
        "        temp_texts,          # Features from the temporary set\n",
        "        temp_labels_str,     # Labels from the temporary set (original strings)\n",
        "        test_size=0.5,       # 50% of temp_texts for test_texts\n",
        "        random_state=2025,     # For reproducibility\n",
        "        stratify=temp_labels_str  # Ensures proportional distribution\n",
        "\n",
        "\n",
        "\n",
        "    # train_texts, train_labels_str = load_and_prepare_data(\"/content/drive/MyDrive/Data/splits/train.csv\",cls_token=ACTUAL_CLS_TOKEN, sep_token=ACTUAL_SEP_TOKEN)\n",
        "    # val_texts, val_labels_str = load_and_prepare_data(\"/content/drive/MyDrive/Data/splits/val.csv\",cls_token=ACTUAL_CLS_TOKEN, sep_token=ACTUAL_SEP_TOKEN)\n",
        "    # test_texts, test_labels_str = load_and_prepare_data(\"/content/drive/MyDrive/Data/splits/val.csv\",cls_token=ACTUAL_CLS_TOKEN, sep_token=ACTUAL_SEP_TOKEN)\n",
        "    )\n",
        "\n",
        "    print(f\"Total examples: {len(data_texts)}\")\n",
        "    print(f\"Train examples: {len(train_texts)}, Validation examples: {len(val_texts)}, Test examples: {len(test_texts)}\")\n",
        "\n",
        "    # --- Verification of Label Distribution ---\n",
        "    print(\"\\nOriginal dataset label distribution:\")\n",
        "    print(pd.Series(data_labels_str).value_counts(normalize=True).sort_index())\n",
        "\n",
        "    print(\"\\nTraining set label distribution:\")\n",
        "    print(pd.Series(train_labels_str).value_counts(normalize=True).sort_index())\n",
        "\n",
        "    print(\"\\nValidation set label distribution:\")\n",
        "    print(pd.Series(val_labels_str).value_counts(normalize=True).sort_index())\n",
        "\n",
        "    print(\"\\nTest set label distribution:\")\n",
        "    print(pd.Series(test_labels_str).value_counts(normalize=True).sort_index())\n",
        "    print(f\"Sample train text: {train_texts.iloc[0]}...\") # Print a sample\n",
        "    print(f\"Sample train label: {train_labels_str.iloc[0]}\")\n",
        "    print(f\"Unique labels in training data: {train_labels_str.unique()}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: One or more data files not found. Please check file paths.\")\n",
        "    # Exiting or using dummy data if files are not present\n",
        "    # For demonstration, let's assume the script should stop if data isn't found\n",
        "    exit()\n",
        "except ValueError as ve:\n",
        "    print(ve)\n",
        "    exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqO2RKctTx-0",
        "outputId": "2c37404c-aef2-48da-e6ef-522a00c01ea1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizing texts...\n"
          ]
        }
      ],
      "source": [
        "# --- 2. Tokenization ---\n",
        "MAX_LENGTH = 384  # Max sequence length for tokenizer\n",
        "\n",
        "print(\"Tokenizing texts...\")\n",
        "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=MAX_LENGTH)\n",
        "val_encodings = tokenizer(val_texts.tolist(), truncation=True, padding=True, max_length=MAX_LENGTH)\n",
        "test_encodings = tokenizer(test_texts.tolist(), truncation=True, padding=True, max_length=MAX_LENGTH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQZlQozUTyhv",
        "outputId": "cafba045-5abf-4672-9e5a-59eb8c1f2cc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating datasets...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PERCENTILE ANALYSIS:\n",
            "   50.0th percentile:    129 tokens\n",
            "   75.0th percentile:    162 tokens\n",
            "   90.0th percentile:    200 tokens\n",
            "   95.0th percentile:    227 tokens\n",
            "   98.0th percentile:    271 tokens\n",
            "   99.0th percentile:    307 tokens\n",
            "   99.5th percentile:    346 tokens\n",
            "   99.9th percentile:    408 tokens\n",
            "\n",
            "Recommended MAX_LENGTH for 98% coverage: 271\n",
            "Current MAX_LENGTH: 384\n"
          ]
        }
      ],
      "source": [
        "# --- 3. Custom Dataset ---\n",
        "class CommentDataset(Dataset):\n",
        "    def __init__(self, encodings, string_labels):\n",
        "        self.encodings = encodings\n",
        "        if hasattr(string_labels, 'tolist'): # Handles pandas Series\n",
        "            self.string_labels = string_labels.tolist()\n",
        "        else:\n",
        "            self.string_labels = string_labels\n",
        "\n",
        "        # Validate labels during initialization\n",
        "        if not all(isinstance(label, str) for label in self.string_labels):\n",
        "            raise ValueError(\"All labels must be strings.\")\n",
        "        if not all(label in LABEL_TO_ID for label in self.string_labels):\n",
        "            unknown = set(self.string_labels) - set(LABEL_TO_ID.keys())\n",
        "            raise ValueError(f\"Unknown labels found: {unknown}. Known: {list(LABEL_TO_ID.keys())}\")\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx], dtype=torch.long) for key, val in self.encodings.items()}\n",
        "        label_str = self.string_labels[idx]\n",
        "        item['labels'] = torch.tensor(LABEL_TO_ID[label_str], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.string_labels)\n",
        "\n",
        "def token_analyzing(all_texts):\n",
        "    \"\"\"Simple percentile analysis for all sequences\"\"\"\n",
        "\n",
        "    # Get actual lengths for all texts\n",
        "    all_lengths = []\n",
        "    for text in all_texts:\n",
        "        tokens = tokenizer.encode(text, add_special_tokens=True)\n",
        "        all_lengths.append(len(tokens))\n",
        "\n",
        "    # Percentile analysis\n",
        "    percentiles = [50, 75, 90, 95, 98, 99, 99.5, 99.9]\n",
        "    print(f\"PERCENTILE ANALYSIS:\")\n",
        "    for p in percentiles:\n",
        "        value = np.percentile(all_lengths, p)\n",
        "        print(f\"   {p:4.1f}th percentile: {value:6.0f} tokens\")\n",
        "\n",
        "    return int(np.percentile(all_lengths, 98))\n",
        "\n",
        "print(\"Creating datasets...\")\n",
        "\n",
        "# Combine all texts for analysis\n",
        "all_texts = train_texts.tolist() + val_texts.tolist() + test_texts.tolist()\n",
        "recommended_98th = token_analyzing(all_texts)\n",
        "\n",
        "print(f\"\\nRecommended MAX_LENGTH for 98% coverage: {recommended_98th}\")\n",
        "print(f\"Current MAX_LENGTH: {MAX_LENGTH}\")\n",
        "\n",
        "if not train_texts.empty:\n",
        "    train_dataset = CommentDataset(train_encodings, train_labels_str)\n",
        "else:\n",
        "    print(\"Train dataset is empty. Cannot create CommentDataset for training.\")\n",
        "    train_dataset = None\n",
        "\n",
        "if not val_texts.empty:\n",
        "    val_dataset = CommentDataset(val_encodings, val_labels_str)\n",
        "else:\n",
        "    print(\"Validation dataset is empty. Cannot create CommentDataset for validation.\")\n",
        "    val_dataset = None\n",
        "\n",
        "if not test_texts.empty:\n",
        "    test_dataset = CommentDataset(test_encodings, test_labels_str)\n",
        "else:\n",
        "    print(\"Test dataset is empty. Cannot create CommentDataset for testing.\")\n",
        "    test_dataset = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BeafO9VfzV8",
        "outputId": "19150841-a607-42c6-c73b-17634a9c8d6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying oversampling to training data...\n",
            "Original distribution:\n",
            "  KHONG_PHAN_DONG: 5395\n",
            "  KHONG_LIEN_QUAN: 8003\n",
            "  PHAN_DONG: 1731\n",
            "  PHAN_DONG: 1731 -> 5602 (oversampled)\n",
            "  KHONG_PHAN_DONG: 5395 -> 5602 (oversampled)\n",
            "  KHONG_LIEN_QUAN: 8003 (no change)\n",
            "\n",
            "Final balanced distribution:\n",
            "  PHAN_DONG: 5602\n",
            "  KHONG_PHAN_DONG: 5602\n",
            "  KHONG_LIEN_QUAN: 8003\n",
            "Re-tokenizing balanced training data...\n",
            "Original training size: 15129\n",
            "Balanced training size: 19207\n"
          ]
        }
      ],
      "source": [
        "# Add this cell after your dataset creation\n",
        "from collections import Counter\n",
        "from sklearn.utils import resample\n",
        "import pandas as pd\n",
        "\n",
        "def oversample_minority_classes(texts, labels, target_ratio=0.8):\n",
        "    \"\"\"\n",
        "    Oversample minority classes to achieve better balance.\n",
        "\n",
        "    Args:\n",
        "        texts: Text data (pandas Series)\n",
        "        labels: Labels (pandas Series)\n",
        "        target_ratio: Target ratio for minority class relative to majority class\n",
        "\n",
        "    Returns:\n",
        "        Balanced texts and labels\n",
        "    \"\"\"\n",
        "    # Convert to DataFrame for easier manipulation\n",
        "    df = pd.DataFrame({'text': texts, 'label': labels})\n",
        "\n",
        "    # Count original distribution\n",
        "    label_counts = Counter(labels)\n",
        "    print(\"Original distribution:\")\n",
        "    for label, count in label_counts.items():\n",
        "        print(f\"  {label}: {count}\")\n",
        "\n",
        "    # Find majority class size\n",
        "    majority_size = max(label_counts.values())\n",
        "    target_minority_size = int(majority_size * target_ratio)\n",
        "\n",
        "    balanced_dfs = []\n",
        "\n",
        "    for label in LABELS:\n",
        "        label_df = df[df['label'] == label]\n",
        "        current_size = len(label_df)\n",
        "\n",
        "        if current_size < target_minority_size:\n",
        "            # Oversample this class\n",
        "            n_samples_needed = target_minority_size - current_size\n",
        "            oversampled = resample(\n",
        "                label_df,\n",
        "                n_samples=n_samples_needed,\n",
        "                random_state=42,\n",
        "                replace=True\n",
        "            )\n",
        "            combined_df = pd.concat([label_df, oversampled], ignore_index=True)\n",
        "            print(f\"  {label}: {current_size} -> {len(combined_df)} (oversampled)\")\n",
        "        else:\n",
        "            combined_df = label_df\n",
        "            print(f\"  {label}: {current_size} (no change)\")\n",
        "\n",
        "        balanced_dfs.append(combined_df)\n",
        "\n",
        "    # Combine all classes\n",
        "    balanced_df = pd.concat(balanced_dfs, ignore_index=True)\n",
        "\n",
        "    # Shuffle the dataset\n",
        "    balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    print(f\"\\nFinal balanced distribution:\")\n",
        "    final_counts = Counter(balanced_df['label'])\n",
        "    for label, count in final_counts.items():\n",
        "        print(f\"  {label}: {count}\")\n",
        "\n",
        "    return balanced_df['text'], balanced_df['label']\n",
        "\n",
        "# Apply oversampling to training data only\n",
        "print(\"Applying oversampling to training data...\")\n",
        "balanced_train_texts, balanced_train_labels = oversample_minority_classes(\n",
        "    train_texts,\n",
        "    train_labels_str,\n",
        "    target_ratio=0.7  # Minority classes will be 70% of majority class size\n",
        ")\n",
        "\n",
        "# Re-tokenize balanced training data\n",
        "print(\"Re-tokenizing balanced training data...\")\n",
        "balanced_train_encodings = tokenizer(\n",
        "    balanced_train_texts.tolist(),\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=MAX_LENGTH\n",
        ")\n",
        "\n",
        "# Create new balanced training dataset\n",
        "balanced_train_dataset = CommentDataset(balanced_train_encodings, balanced_train_labels)\n",
        "\n",
        "print(f\"Original training size: {len(train_dataset)}\")\n",
        "print(f\"Balanced training size: {len(balanced_train_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EUuWKClqT457"
      },
      "outputs": [],
      "source": [
        "# --- Enhanced Metrics for Imbalanced Data ---\n",
        "def compute_balanced_metrics(pred):\n",
        "    \"\"\"Enhanced metrics optimized for imbalanced Vietnamese classification.\"\"\"\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "\n",
        "    # Multiple F1 variants for comparison\n",
        "    weighted_precision, weighted_recall, weighted_f1, _ = precision_recall_fscore_support(labels, preds, average='weighted', zero_division=0)\n",
        "    macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
        "\n",
        "    # Overall accuracy\n",
        "    acc = accuracy_score(labels, preds)\n",
        "\n",
        "    # Per-class metrics (crucial for imbalanced data)\n",
        "    per_class_precision, per_class_recall, per_class_f1, _ = precision_recall_fscore_support(\n",
        "        labels, preds, average=None, zero_division=0\n",
        "    )\n",
        "\n",
        "    # Balanced accuracy (better than regular accuracy for imbalanced data)\n",
        "    from sklearn.metrics import balanced_accuracy_score\n",
        "    balanced_acc = balanced_accuracy_score(labels, preds)\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'balanced_accuracy': balanced_acc,\n",
        "\n",
        "        # F1 variants\n",
        "        'f1_weighted': weighted_f1,      # Your current metric (biased)\n",
        "        'f1_macro': macro_f1,            # BETTER: Equal weight to all classes\n",
        "\n",
        "        # Overall precision/recall\n",
        "        'precision_weighted': weighted_precision,\n",
        "        'recall_weighted': weighted_recall,\n",
        "        'precision_macro': macro_precision,\n",
        "        'recall_macro': macro_recall,\n",
        "\n",
        "        # Per-class metrics (monitor minority class performance)\n",
        "        'f1_phan_dong': per_class_f1[0],           # Minority class F1\n",
        "        'f1_khong_phan_dong': per_class_f1[1],\n",
        "        'f1_khong_lien_quan': per_class_f1[2],     # Majority class F1\n",
        "\n",
        "        # Per-class recall (important for minority class)\n",
        "        'recall_phan_dong': per_class_recall[0],   # Critical metric!\n",
        "        'recall_khong_phan_dong': per_class_recall[1],\n",
        "        'recall_khong_lien_quan': per_class_recall[2],\n",
        "    }\n",
        "from transformers import EarlyStoppingCallback\n",
        "# Early stopping to prevent overfitting\n",
        "early_stopping = EarlyStoppingCallback(\n",
        "    early_stopping_patience=2,      # Stop if no improvement for 2 epochs\n",
        "    early_stopping_threshold=0.005  # Minimum improvement threshold\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "7xdIuzgKT6sC",
        "outputId": "eee2b072-b17f-4abb-afb6-3cfe466e0a14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model: uitnlp/CafeBERT for sequence classification with 3 labels.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at uitnlp/CafeBERT and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2526' max='2526' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2526/2526 55:52, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Balanced Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>Precision Weighted</th>\n",
              "      <th>Recall Weighted</th>\n",
              "      <th>Precision Macro</th>\n",
              "      <th>Recall Macro</th>\n",
              "      <th>F1 Phan Dong</th>\n",
              "      <th>F1 Khong Phan Dong</th>\n",
              "      <th>F1 Khong Lien Quan</th>\n",
              "      <th>Recall Phan Dong</th>\n",
              "      <th>Recall Khong Phan Dong</th>\n",
              "      <th>Recall Khong Lien Quan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.743100</td>\n",
              "      <td>0.710554</td>\n",
              "      <td>0.699630</td>\n",
              "      <td>0.633035</td>\n",
              "      <td>0.698999</td>\n",
              "      <td>0.642604</td>\n",
              "      <td>0.701572</td>\n",
              "      <td>0.699630</td>\n",
              "      <td>0.658363</td>\n",
              "      <td>0.633035</td>\n",
              "      <td>0.505155</td>\n",
              "      <td>0.645614</td>\n",
              "      <td>0.777044</td>\n",
              "      <td>0.451613</td>\n",
              "      <td>0.682493</td>\n",
              "      <td>0.765000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.595200</td>\n",
              "      <td>0.609888</td>\n",
              "      <td>0.739291</td>\n",
              "      <td>0.661792</td>\n",
              "      <td>0.734109</td>\n",
              "      <td>0.678272</td>\n",
              "      <td>0.733620</td>\n",
              "      <td>0.739291</td>\n",
              "      <td>0.703675</td>\n",
              "      <td>0.661792</td>\n",
              "      <td>0.542105</td>\n",
              "      <td>0.681436</td>\n",
              "      <td>0.811276</td>\n",
              "      <td>0.474654</td>\n",
              "      <td>0.661721</td>\n",
              "      <td>0.849000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.514100</td>\n",
              "      <td>0.631883</td>\n",
              "      <td>0.746166</td>\n",
              "      <td>0.673503</td>\n",
              "      <td>0.741244</td>\n",
              "      <td>0.690519</td>\n",
              "      <td>0.741271</td>\n",
              "      <td>0.746166</td>\n",
              "      <td>0.716221</td>\n",
              "      <td>0.673503</td>\n",
              "      <td>0.569191</td>\n",
              "      <td>0.687692</td>\n",
              "      <td>0.814674</td>\n",
              "      <td>0.502304</td>\n",
              "      <td>0.663205</td>\n",
              "      <td>0.855000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.387000</td>\n",
              "      <td>0.680359</td>\n",
              "      <td>0.758329</td>\n",
              "      <td>0.717675</td>\n",
              "      <td>0.757815</td>\n",
              "      <td>0.717864</td>\n",
              "      <td>0.757530</td>\n",
              "      <td>0.758329</td>\n",
              "      <td>0.718245</td>\n",
              "      <td>0.717675</td>\n",
              "      <td>0.623853</td>\n",
              "      <td>0.711916</td>\n",
              "      <td>0.817822</td>\n",
              "      <td>0.626728</td>\n",
              "      <td>0.700297</td>\n",
              "      <td>0.826000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.271900</td>\n",
              "      <td>0.764460</td>\n",
              "      <td>0.745108</td>\n",
              "      <td>0.702064</td>\n",
              "      <td>0.745841</td>\n",
              "      <td>0.702457</td>\n",
              "      <td>0.747458</td>\n",
              "      <td>0.745108</td>\n",
              "      <td>0.703651</td>\n",
              "      <td>0.702064</td>\n",
              "      <td>0.594848</td>\n",
              "      <td>0.709261</td>\n",
              "      <td>0.803262</td>\n",
              "      <td>0.585253</td>\n",
              "      <td>0.732938</td>\n",
              "      <td>0.788000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.251500</td>\n",
              "      <td>0.819301</td>\n",
              "      <td>0.745637</td>\n",
              "      <td>0.705992</td>\n",
              "      <td>0.746316</td>\n",
              "      <td>0.703035</td>\n",
              "      <td>0.747125</td>\n",
              "      <td>0.745637</td>\n",
              "      <td>0.700267</td>\n",
              "      <td>0.705992</td>\n",
              "      <td>0.597285</td>\n",
              "      <td>0.705969</td>\n",
              "      <td>0.805850</td>\n",
              "      <td>0.608295</td>\n",
              "      <td>0.710682</td>\n",
              "      <td>0.799000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training finished.\n"
          ]
        }
      ],
      "source": [
        "# --- 4. Model Loading ---\n",
        "print(f\"Loading model: {MODEL_NAME} for sequence classification with {NUM_LABELS} labels.\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=NUM_LABELS,\n",
        ")\n",
        "# --- 5. Training Arguments ---\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    learning_rate= 1e-5,\n",
        "    num_train_epochs= 6,\n",
        "    per_device_train_batch_size= 12,\n",
        "    per_device_eval_batch_size= 24,\n",
        "    warmup_ratio= 0.15,\n",
        "    weight_decay= 0.02,\n",
        "    gradient_accumulation_steps= 3,\n",
        "    logging_dir=LOGGING_DIR,\n",
        "    logging_steps=50,\n",
        "    eval_strategy=\"epoch\", # Changed from evaluation_strategy\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=1,    # Only keep the best model\n",
        "    bf16=True,\n",
        "    load_best_model_at_end=True, # Load the best model at the end of training\n",
        "    metric_for_best_model=\"eval_f1_macro\",\n",
        "    greater_is_better=True,\n",
        "    report_to=\"none\", # No external reporting like wandb/tensorboard\n",
        ")\n",
        "# --- 7. Trainer Initialization and Training ---\n",
        "if train_dataset and val_dataset:\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_balanced_metrics,\n",
        "        callbacks=[early_stopping]\n",
        "    )\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    trainer.train()\n",
        "    print(\"Training finished.\")\n",
        "\n",
        "    # # Save the fine-tuned model and tokenizer\n",
        "    # print(\"Saving model and tokenizer...\")\n",
        "    # model.save_pretrained(OUTPUT_DIR + \"/best_model\")\n",
        "    # tokenizer.save_pretrained(OUTPUT_DIR + \"/best_model\")\n",
        "    # print(f\"Model and tokenizer saved to {OUTPUT_DIR}/best_model\")\n",
        "\n",
        "else:\n",
        "    print(\"Cannot start training due to empty train or validation dataset.\")\n",
        "    trainer = None # Ensure trainer is None if not initialized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "id": "DltzZN0YT8Xb",
        "outputId": "103d9c3e-fa53-446b-c0d9-b2869158b85a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating on the test set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set evaluation results (from trainer.evaluate):\n",
            "  eval_loss: 0.6807\n",
            "  eval_accuracy: 0.7495\n",
            "  eval_balanced_accuracy: 0.6940\n",
            "  eval_f1_weighted: 0.7484\n",
            "  eval_f1_macro: 0.6997\n",
            "  eval_precision_weighted: 0.7477\n",
            "  eval_recall_weighted: 0.7495\n",
            "  eval_precision_macro: 0.7063\n",
            "  eval_recall_macro: 0.6940\n",
            "  eval_f1_phan_dong: 0.5811\n",
            "  eval_f1_khong_phan_dong: 0.7026\n",
            "  eval_f1_khong_lien_quan: 0.8155\n",
            "  eval_recall_phan_dong: 0.5556\n",
            "  eval_recall_khong_phan_dong: 0.7052\n",
            "  eval_recall_khong_lien_quan: 0.8212\n",
            "  eval_runtime: 15.7375\n",
            "  eval_samples_per_second: 120.2220\n",
            "  eval_steps_per_second: 5.0200\n",
            "  epoch: 6.0000\n",
            "\n",
            "Getting predictions for detailed classification report on the test set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `XLMRobertaSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report on Test Set (Corrected Order):\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "      PHAN_DONG     0.6091    0.5556    0.5811       216\n",
            "KHONG_PHAN_DONG     0.7000    0.7052    0.7026       675\n",
            "KHONG_LIEN_QUAN     0.8099    0.8212    0.8155      1001\n",
            "\n",
            "       accuracy                         0.7495      1892\n",
            "      macro avg     0.7063    0.6940    0.6997      1892\n",
            "   weighted avg     0.7477    0.7495    0.7484      1892\n",
            "\n",
            "\n",
            "Script finished.\n"
          ]
        }
      ],
      "source": [
        "# --- 8. Evaluation on Test Set  ---\n",
        "if test_dataset and trainer:\n",
        "    print(\"\\nEvaluating on the test set...\")\n",
        "    results = trainer.evaluate(test_dataset) # This provides eval_loss, eval_accuracy etc. using compute_metrics\n",
        "    print(\"Test set evaluation results (from trainer.evaluate):\")\n",
        "    for key, value in results.items():\n",
        "        print(f\"  {key}: {value:.4f}\") # Format output\n",
        "\n",
        "    print(\"\\nGetting predictions for detailed classification report on the test set...\")\n",
        "    predictions_output = trainer.predict(test_dataset)\n",
        "\n",
        "    predicted_indices = predictions_output.predictions.argmax(-1) # Get the index of the highest logit\n",
        "    # Convert numerical predictions back to string labels using the ID_TO_LABEL map\n",
        "    predicted_labels_text = [ID_TO_LABEL[idx] for idx in predicted_indices]\n",
        "\n",
        "    # Get true string labels from your test data (e.g., from test_labels_str Series)\n",
        "    true_labels_text = test_labels_str.tolist()\n",
        "\n",
        "    print(\"\\nClassification Report on Test Set (Corrected Order):\")\n",
        "    # Add the 'labels' parameter to ensure the report order matches target_names\n",
        "    print(classification_report(\n",
        "        true_labels_text,\n",
        "        predicted_labels_text,\n",
        "        labels=LABELS,\n",
        "        target_names=LABELS,\n",
        "        digits=4\n",
        "    ))\n",
        "else:\n",
        "    print(\"Cannot evaluate on test set: Test dataset is empty or trainer was not initialized.\")\n",
        "\n",
        "print(\"\\nScript finished.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TVvaI8esK454"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxMw6mqE5KYe",
        "outputId": "30c3334a-d09a-43d3-a0eb-d89c56185113"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model and tokenizer...\n",
            "Model and tokenizer saved to /content/drive/MyDrive/ChongPha_Ver2/VisoBERT/OUTPUT/best_model\n"
          ]
        }
      ],
      "source": [
        "    # Save the fine-tuned model and tokenizer\n",
        "    print(\"Saving model and tokenizer...\")\n",
        "    model.save_pretrained(OUTPUT_DIR + \"/best_model\")\n",
        "    tokenizer.save_pretrained(OUTPUT_DIR + \"/best_model\")\n",
        "    print(f\"Model and tokenizer saved to {OUTPUT_DIR}/best_model\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
